{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YofzhXihFB4"
   },
   "source": [
    "XGBoost is a boosting library with parallel, GPU, and distributed execution support. It has help many machin learning engineers and data scientists to win Kaggle competitions. \n",
    "\n",
    "Furthermore, it provides an interface that resembles scikit-learn interface. Thus, someone already farmilar with the interface is able to quickly utilize the library. Additionally, it allows for very fine control over the ensemble's creation. It supports monotonic contraints (that is the predicted value should only increase or decrease, relative to a specific feature), as well as feature interaction constraints (for example, if a decision tree creates a node that splits by age, it should not use sex as a splitting feature for all children of that specific node). Finally it adds an additional regularization parameter gamma, which further reduces the overfitting capabilities of the gernerated ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u3zsGldUiGdy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "# Step 1: Import libraries and data\n",
    "from sklearn.datasets import load_diabetes\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "diabetes = load_diabetes()\n",
    "train_size = 400\n",
    "train_x, train_y = diabetes.data[:train_size], diabetes.target[:train_size]\n",
    "test_x, test_y = diabetes.data[train_size:], diabetes.target[train_size:]\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7PpOuY7Gfg4x"
   },
   "outputs": [],
   "source": [
    "#Step 2: Create the ensemble\n",
    "ensemble_size = 200\n",
    "ensemble = XGBRegressor(n_estimators=ensemble_size, n_jobs=4, max_depth=1, learning_rate=0.1, objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IyTx3Ldgj1AB"
   },
   "outputs": [],
   "source": [
    "# Step 3: Evaluate the ensemble\n",
    "ensemble.fit(train_x,train_y)\n",
    "predictions = ensemble.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yv_lqvGxj-fR",
    "outputId": "bcfa1afe-f2a8-4d70-8019-bbaad214d9bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: \n",
      "R-squared: 0.65\n",
      "MSE: 1932.91\n"
     ]
    }
   ],
   "source": [
    "#Step 4: print the metrics\n",
    "r2= metrics.r2_score(test_y, predictions)\n",
    "mse = metrics.mean_squared_error(test_y,predictions)\n",
    "print('XGBoost: ')\n",
    "print('R-squared: %.2f' % r2)\n",
    "print('MSE: %.2f'%mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTQm6VXYkW7Q"
   },
   "source": [
    "XGBoost achives an R-squared of 0.65 and an MSE of 1932.9. This is the best performance out of all the boosting method we did test and implement."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Udemy XGBoost Implementation for Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
