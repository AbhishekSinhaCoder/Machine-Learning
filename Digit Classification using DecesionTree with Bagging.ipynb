{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QLKXlDoGnKLF"
   },
   "outputs": [],
   "source": [
    "# Step 1: import libraries and data\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "digits = load_digits()\n",
    "train_size = 1500\n",
    "# Split the train and test set\n",
    "train_x, train_y =digits.data[:train_size], digits.target[:train_size]\n",
    "test_x, test_y =digits.data[train_size:], digits.target[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "240mSfXHvkpH"
   },
   "source": [
    "We will create our bootstrap samples and train the models.\n",
    "\n",
    "Note that we do not use np.random.choice. Instead we will generate an array of indices with np.random.randint(0,train_size, size = train_size), as this will enable us to choose both the features and the corresponding targets for each bootstrap sample. We store each base learner in the base_learners list for the ease of acces later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "riSx4ldHv8P5"
   },
   "outputs": [],
   "source": [
    "# Step 2: Create our bootstrap samples and train the classifiers\n",
    "ensemble_size = 10\n",
    "base_learners = []\n",
    "\n",
    "for _ in range(ensemble_size):\n",
    "  # We sample indices in order to access features and targets\n",
    "  bootstrap_sample_indices = np.random.randint(0, train_size, size=train_size)\n",
    "  bootstrap_x = train_x[bootstrap_sample_indices]\n",
    "  bootstrap_y = train_y[bootstrap_sample_indices]\n",
    "  dtree = DecisionTreeClassifier()\n",
    "  dtree.fit(bootstrap_x, bootstrap_y)\n",
    "  base_learners.append(dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9FL7_ZsxFAw"
   },
   "source": [
    "Next we will predict the targets of the test set with each base learner and store their preidctions as well as their evaluated accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xkxOBkWHxEak"
   },
   "outputs": [],
   "source": [
    "# Step 3: We will predict with the base learners and evaluate them\n",
    "\n",
    "base_predictions = []\n",
    "base_accuracy = []\n",
    "for learner in base_learners:\n",
    "    predictions = learner.predict(test_x)\n",
    "    base_predictions.append(predictions)\n",
    "    acc = metrics.accuracy_score(test_y, predictions)\n",
    "    base_accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5FaZ1T5xu_m"
   },
   "source": [
    "Now that we have each base learner's predictions in base_predictions, we can combine them with hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0u2qf5M-x5vm"
   },
   "outputs": [],
   "source": [
    "# Step 4: Combine the base learners' predictions\n",
    "ensemble_predictions = []\n",
    "# Find the most voted class for each test instance\n",
    "for i in range(len(test_y)):\n",
    "    # Count the votes for each class\n",
    "    counts = [0 for _ in range(10)]\n",
    "    for learner_predictions in base_predictions:\n",
    "        counts[learner_predictions[i]] = counts[learner_predictions[i]]+1\n",
    "\n",
    "    # Find the class with most votes\n",
    "    final = np.argmax(counts)\n",
    "    # Add the class to the final predictions\n",
    "    ensemble_predictions.append(final)\n",
    "\n",
    "ensemble_acc = metrics.accuracy_score(test_y, ensemble_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rQ_HKFZyxsp"
   },
   "source": [
    "Finally we will print the accuracy of each base learner as well as the ensemble's accuracy, sorted in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VMcSxg0y5yW",
    "outputId": "194f226d-d6e4-4b3d-90ad-5821a81d0af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Learners: \n",
      "------------------------------\n",
      "Learner 1: 0.74\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 2: 0.74\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 3: 0.76\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 4: 0.77\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 5: 0.77\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 6: 0.77\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 7: 0.78\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 8: 0.78\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 9: 0.79\n",
      "------------------------------\n",
      "Bagging: 0.87\n",
      "Learner 10: 0.80\n",
      "------------------------------\n",
      "Bagging: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Print the accuracies\n",
    "print('Base Learners: ')\n",
    "print('-'*30)\n",
    "for index, acc in enumerate(sorted(base_accuracy)):\n",
    "  print(f'Learner {index + 1}: %.2f' %acc)\n",
    "  print('-'*30)\n",
    "  print('Bagging: %.2f'% ensemble_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3TWzc3jzebb"
   },
   "source": [
    "It is eveident that the ensemble'accuracy is almost 7% higher than the best-performing base model. This is a considerable improvement, especiialy if we take into account that this ensemble consists of identical base learners."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Udemy Bagging implementatio Method 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
